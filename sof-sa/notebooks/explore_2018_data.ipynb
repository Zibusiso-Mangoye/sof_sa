{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing exploratory data analysis on data from the StakeOverFlow developer survey from the years 2018 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The purpose of this notebook is to analyze StackOverflow Developer Survey data in order to answer the following questions:\\\n",
    "***Developer's choice of tech stack?***\\\n",
    "This is question is broken down to four parts namely:\n",
    "- Question 1 Which programming languages have gained popularity from 2018 to 2021?\n",
    "- Question 2 Which database services have gained popularity from 2018 to 2021?\n",
    "- Question 3 Which cloud platforms have gained popularity from 2018 to 2021?\n",
    "- Question 4 Which web frameworks have gained popularity from 2018 to 2021?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "Extracting the data\\\n",
    "Data Model\\\n",
    "Transforming the data\\\n",
    "Loading in the data into a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While writing this notebook, the data was stored locally in my computer therefore to follow along with this note book you will need to download the data from here : https://insights.stackoverflow.com/survey/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/09/22 05:46:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'public_2018_data'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>               <a href=\"file://C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\io\\data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\io\\data_catalog.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/09/22 05:46:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'public_2018_data'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m               \u001b]8;id=555644;file://C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\io\\data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=587120;file://C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\io\\data_catalog.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/09/22 05:46:50] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\ex <a href=\"file://C:\\Users\\znman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\znman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tras\\datasets\\pandas\\csv_dataset.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>: DtypeWarning: Columns         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">117</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">124</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">125</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">)</span> have mixed types.   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Specify dtype option on import or set <span style=\"color: #808000; text-decoration-color: #808000\">low_memory</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>.                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">pd.read_csv</span><span style=\"font-weight: bold\">(</span>load_path, **self._load_args<span style=\"font-weight: bold\">)</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/09/22 05:46:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m C:\\Users\\znman\\Desktop\\Projects\\sof_sa\\venv\\lib\\site-packages\\kedro\\ex \u001b]8;id=867349;file://C:\\Users\\znman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=628273;file://C:\\Users\\znman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         tras\\datasets\\pandas\\csv_dataset.py:\u001b[1;36m160\u001b[0m: DtypeWarning: Columns         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m,\u001b[1;36m12\u001b[0m,\u001b[1;36m13\u001b[0m,\u001b[1;36m14\u001b[0m,\u001b[1;36m15\u001b[0m,\u001b[1;36m16\u001b[0m,\u001b[1;36m50\u001b[0m,\u001b[1;36m51\u001b[0m,\u001b[1;36m52\u001b[0m,\u001b[1;36m53\u001b[0m,\u001b[1;36m55\u001b[0m,\u001b[1;36m56\u001b[0m,\u001b[1;36m57\u001b[0m,\u001b[1;36m58\u001b[0m,\u001b[1;36m59\u001b[0m,\u001b[1;36m60\u001b[0m,\u001b[1;36m61\u001b[0m,\u001b[1;36m62\u001b[0m,\u001b[1;36m63\u001b[0m,\u001b[1;36m64\u001b[0m,\u001b[1;36m65\u001b[0m,\u001b[1;36m66\u001b[0m,\u001b[1;36m67\u001b[0m,\u001b[1;36m6\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m8\u001b[0m,\u001b[1;36m69\u001b[0m,\u001b[1;36m70\u001b[0m,\u001b[1;36m71\u001b[0m,\u001b[1;36m72\u001b[0m,\u001b[1;36m73\u001b[0m,\u001b[1;36m74\u001b[0m,\u001b[1;36m75\u001b[0m,\u001b[1;36m76\u001b[0m,\u001b[1;36m77\u001b[0m,\u001b[1;36m78\u001b[0m,\u001b[1;36m79\u001b[0m,\u001b[1;36m80\u001b[0m,\u001b[1;36m81\u001b[0m,\u001b[1;36m82\u001b[0m,\u001b[1;36m83\u001b[0m,\u001b[1;36m84\u001b[0m,\u001b[1;36m85\u001b[0m,\u001b[1;36m93\u001b[0m,\u001b[1;36m94\u001b[0m,\u001b[1;36m95\u001b[0m,\u001b[1;36m96\u001b[0m,\u001b[1;36m97\u001b[0m,\u001b[1;36m98\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         ,\u001b[1;36m99\u001b[0m,\u001b[1;36m100\u001b[0m,\u001b[1;36m101\u001b[0m,\u001b[1;36m102\u001b[0m,\u001b[1;36m103\u001b[0m,\u001b[1;36m104\u001b[0m,\u001b[1;36m105\u001b[0m,\u001b[1;36m106\u001b[0m,\u001b[1;36m107\u001b[0m,\u001b[1;36m108\u001b[0m,\u001b[1;36m109\u001b[0m,\u001b[1;36m110\u001b[0m,\u001b[1;36m111\u001b[0m,\u001b[1;36m112\u001b[0m,\u001b[1;36m113\u001b[0m,\u001b[1;36m114\u001b[0m,\u001b[1;36m115\u001b[0m,\u001b[1;36m11\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m6\u001b[0m,\u001b[1;36m117\u001b[0m,\u001b[1;36m118\u001b[0m,\u001b[1;36m119\u001b[0m,\u001b[1;36m120\u001b[0m,\u001b[1;36m121\u001b[0m,\u001b[1;36m122\u001b[0m,\u001b[1;36m123\u001b[0m,\u001b[1;36m124\u001b[0m,\u001b[1;36m125\u001b[0m,\u001b[1;36m126\u001b[0m,\u001b[1;36m127\u001b[0m,\u001b[1;36m128\u001b[0m\u001b[1m)\u001b[0m have mixed types.   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Specify dtype option on import or set \u001b[33mlow_memory\u001b[0m=\u001b[3;91mFalse\u001b[0m.                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           return \u001b[1;35mpd.read_csv\u001b[0m\u001b[1m(\u001b[0mload_path, **self._load_args\u001b[1m)\u001b[0m                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2018 = catalog.load('public_2018_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Hobby</th>\n",
       "      <th>OpenSource</th>\n",
       "      <th>Country</th>\n",
       "      <th>Student</th>\n",
       "      <th>Employment</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>UndergradMajor</th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>DevType</th>\n",
       "      <th>...</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Gender</th>\n",
       "      <th>SexualOrientation</th>\n",
       "      <th>EducationParents</th>\n",
       "      <th>RaceEthnicity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MilitaryUS</th>\n",
       "      <th>SurveyTooLong</th>\n",
       "      <th>SurveyEasy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed part-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Mathematics or statistics</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Black or of African descent</td>\n",
       "      <td>25 - 34 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Very easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>A natural science (ex. biology, chemistry, phy...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Database administrator;DevOps specialist;Full-...</td>\n",
       "      <td>...</td>\n",
       "      <td>Daily or almost every day</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>35 - 44 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Associate degree</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Engineering manager;Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>100 to 499 employees</td>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>I don't typically exercise</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>35 - 44 years old</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Yes, part-time</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Data or business analyst;Desktop or enterprise...</td>\n",
       "      <td>...</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>18 - 24 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis is for practice only as the use is minimal \n",
    "# Here a staging database is used to store raw data from the csv files then loaded back into a dataframe\n",
    "# however an sql query has been executed against the raw data.\n",
    "# This would be useful if there needs to be continuous requests to the vendor and also makes it easy to follow\n",
    "# an alternate transformation route.\n",
    "\n",
    "# load data into staging database\n",
    "catalog.save('stackoverflow2018_dataset', df2018) \n",
    "\n",
    "# Using kedro datasets an sql query is run when the data is loaded back into the pipeline.\n",
    "# See query in catalog file 'sof-sa\\conf\\base\\catalog_sqltables.yml'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2018.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1\n",
    "from collections import Counter\n",
    "\n",
    "def count_unique_items_in_column(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Counts unique elements in dataframe column. Column must have semicolon separated values or nan values in column\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be modified\n",
    "        column_name (str): column name in dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: new dataframe contain value and count of value in df\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the column passed does not exist in dataframe\n",
    "    \"\"\"\n",
    "    if not column_name in df.columns:\n",
    "        raise ValueError(f\"No column named {column_name} in dataframe.\")\n",
    "    \n",
    "    column_as_list = df[column_name].tolist()\n",
    "    \n",
    "    new_list = []\n",
    "    for list_item in column_as_list: \n",
    "        \n",
    "        # for nan values\n",
    "        if isinstance(list_item, type(None)):\n",
    "            new_list.append(list_item)\n",
    "            \n",
    "        if isinstance(list_item, str): \n",
    "            new_list.extend(list_item.split(\";\"))\n",
    "            \n",
    "    # find the number of occurances of a item in a list\n",
    "    occ = Counter(new_list)\n",
    "    language = []\n",
    "    count = []\n",
    "    for x in occ:\n",
    "        key = x\n",
    "        value = occ[key]\n",
    "        language.append(key)\n",
    "        count.append(value)\n",
    "\n",
    "    df_temp = pd.DataFrame(list(zip(language, count)), columns = [column_name, 'count'])\n",
    "    df_temp.set_index(column_name, inplace=True)\n",
    "    df_temp.sort_values(by='count', ascending=False, inplace=True)\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "def _merge(dataframe_list: list) -> pd.DataFrame:\n",
    "    \"\"\"Merges dataframes on index\n",
    "\n",
    "    Args:\n",
    "        dataframe_list (list): a list of dataframes to merge\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: merged dataframe\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: if the list of dataframes passed is not equal to four\n",
    "    \"\"\"\n",
    "    if len(dataframe_list) != 4:\n",
    "        raise ValueError(\"List of dataframes must be equal to four(4)\")\n",
    "        \n",
    "    df18_19 = pd.merge(dataframe_list[0], dataframe_list[1], left_index=True, right_index=True)\n",
    "    df20_21 = pd.merge(dataframe_list[2], dataframe_list[3], left_index=True, right_index=True)\n",
    "    dfs_merged = pd.merge(df18_19, df20_21, left_index=True, right_index=True)\n",
    "    dfs_merged.columns = ['2018', '2019', '2020', '2021']\n",
    "    \n",
    "    return dfs_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "def display_index_values(df_list: list, column_name: str):\n",
    "    for i in df_list:\n",
    "        df_temp = count_unique_items_in_column(i, column_name)\n",
    "        yield df_temp.index.values\n",
    "        \n",
    "j = display_index_values(df_list, 'web_framework_have_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Frameworks\n",
    "# rename React in 2018 dataset to React.js\n",
    "# rename 'Angular' in 2018 dataset to Angular.js\n",
    "# rename 'Angular/Angular.js' to Angular.js in 2019 dataset\n",
    "# add ASP.NET to 2018 dataset and set it to zero\n",
    "# add jQuery to 2018 dataset and set it to zero\n",
    "# add Vue.js to 2018 dataset and set it to zero\n",
    "# add Flask to 2018 dataset and set it to zero\n",
    "# add Laravel to 2018 dataset and set it to zero\n",
    "# add Express to 2018 dataset and set it to zero\n",
    "# add Ruby on Rails to 2018 dataset and set it to zero\n",
    "# add Drupal on Rails to 2018 dataset and set it to zero\n",
    "df18 = count_unique_items_in_column(df2018, 'web_framework_have_worked_with').rename(index={'React': 'React.js', 'Angular': 'Angular.js', 'Angular/Angular.js': 'Angular.js'})\n",
    "for i in ['ASP.NET', 'jQuery', 'Vue.js', 'Flask', 'Laravel',  'Express', 'Ruby on Rails', 'Drupal']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'web_framework_have_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'web_framework_have_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'web_framework_have_worked_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "web_frameworks = _merge(l)\n",
    "\n",
    "\n",
    "df18 = count_unique_items_in_column(df2018, 'web_framework_want_to_work_with').rename(index={'React': 'React.js', 'Angular': 'Angular.js', 'Angular/Angular.js': 'Angular.js'})\n",
    "for i in ['ASP.NET', 'jQuery', 'Vue.js', 'Flask', 'Laravel',  'Express', 'Ruby on Rails', 'Drupal']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'web_framework_want_to_work_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'web_framework_want_to_work_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'web_framework_want_to_work_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "future_web_frameworks = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'platform_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platforms\n",
    "# Only dealing with cloud platforms : AWS Microsoft Azure Heroku  Google Cloud Platform\t IBM Cloud or Watson\n",
    "# change 'Google Cloud Platform/App Engine' into 'Google Cloud Platform'\n",
    "# change 'Azure' in 2018 dataset to 'Microsoft Azure'\n",
    "df18 = count_unique_items_in_column(df2018, 'platform_worked_with').rename(index={'Google Cloud Platform/App Engine': 'Google Cloud Platform', 'Azure': 'Microsoft Azure'})\n",
    "df19 = count_unique_items_in_column(df2019, 'platform_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'platform_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'platform_worked_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "platforms = _merge(l)\n",
    "\n",
    "df18 = count_unique_items_in_column(df2018, 'platform_desire_next_year').rename(index={'Google Cloud Platform/App Engine': 'Google Cloud Platform', 'Azure': 'Microsoft Azure'})\n",
    "df19 = count_unique_items_in_column(df2019, 'platform_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'platform_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'platform_desire_next_year')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "future_platforms = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'language_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Languages\n",
    "df18 = count_unique_items_in_column(df2018, 'language_worked_with')\n",
    "df19 = count_unique_items_in_column(df2019, 'language_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'language_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'language_worked_with')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "languages = _merge(l)\n",
    "\n",
    "# future_languages\n",
    "df18 = count_unique_items_in_column(df2018, 'language_desire_next_year')\n",
    "df19 = count_unique_items_in_column(df2019, 'language_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'language_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'language_desire_next_year')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "future_languages = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'database_desire_next_year')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases\n",
    "df18 = count_unique_items_in_column(df2018, 'database_worked_with').rename(index={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'})\n",
    "for i in ['Cassandra', 'Couchbase', 'Firebase']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'database_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'database_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'database_worked_with')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "databases = _merge(l)\n",
    "\n",
    "# future_Databases\n",
    "df18 = count_unique_items_in_column(df2018, 'database_desire_next_year').rename(index={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'})\n",
    "for i in ['Couchbase', 'Firebase']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'database_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'database_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'database_desire_next_year')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "future_databases = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_dfs(df_list: list, column_name: str, rename: bool = False, rename_data: dict = {}, fill_missing: bool = False, missing_values: dict = {}):\n",
    "    \"\"\"Merge dataframes into one dataframe. \n",
    "\n",
    "    Args:\n",
    "        df_list (list): list of dataframes to merge\n",
    "        column_name (str): column name to merge dataframes on\n",
    "        rename (bool, optional): option to rename any values or not. Defaults to False.\n",
    "        rename_data (dict, optional): data for renaming. Defaults to {}.\n",
    "        fill_missing (bool, optional): fill in missing data or not. Defaults to False.\n",
    "        missing_values (dict, optional): missing data values. Defaults to {}.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if rename is set to true but no data provided\n",
    "        ValueError: if fill_missing is set to true but no data provided\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : merged dataframe\n",
    "    \"\"\"\n",
    "    if rename:\n",
    "        if len(rename_data) == 0:\n",
    "            raise ValueError('Rename specified as True but no data provided')\n",
    "        \n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name).rename(index=rename_data)\n",
    "    else: \n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name)\n",
    "        \n",
    "    if fill_missing:\n",
    "        if len(missing_values) == 0:\n",
    "            raise ValueError('Fill missing specified as True but no data provided')\n",
    "        \n",
    "        if not rename:\n",
    "            df18 = count_unique_items_in_column(df_list[0], column_name)\n",
    "            \n",
    "        for i in missing_values:\n",
    "            if i not in df18.index.values:\n",
    "                df18.loc[i] = 0\n",
    "                \n",
    "    if not rename and not fill_missing:\n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name) \n",
    "        \n",
    "    df19 = count_unique_items_in_column(df_list[1], column_name)\n",
    "    df20 = count_unique_items_in_column(df_list[2], column_name)\n",
    "    df21 = count_unique_items_in_column(df_list[3], column_name)\n",
    "    \n",
    "    l = [df18, df19, df20, df21]\n",
    "\n",
    "    dfs_merged = _merge(l)\n",
    "    return dfs_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "df = merge_dfs(df_list, 'database_worked_with', rename=True, rename_data={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'}, fill_missing=True, missing_values=['Cassandra', 'Couchbase', 'Firebase'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!!! Transformations for question 1 done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2\n",
    "\n",
    "def age_to_range(number: int) -> str:\n",
    "    \"\"\"Checks if a certain value falls within a certain range then retruns the appropriate string\n",
    "\n",
    "    Args:\n",
    "        number (int): number to be checked\n",
    "\n",
    "    Returns:\n",
    "        str: a string based on the number passed\n",
    "    \"\"\"\n",
    "\n",
    "    if number < 18:\n",
    "        return 'Under 18 years old'\n",
    "    elif number >= 18 and number <= 24:\n",
    "        return '18 - 24 years old'\n",
    "    elif number >= 25 and number <= 30:\n",
    "        return '25 - 30 years old'\n",
    "    elif number >= 31 and number <= 36:\n",
    "        return '31 - 36 years old'\n",
    "    elif number >= 37 and number <= 42:\n",
    "        return '37 - 42 years old'\n",
    "    elif number >= 43 and number <= 48:\n",
    "        return '43 - 48 years old'\n",
    "    elif number >= 49 and number <= 54:\n",
    "        return '49 - 54 years old'\n",
    "    elif number >= 55 and number <= 60:\n",
    "        return '55 - 60 years old'\n",
    "    elif number > 60:\n",
    "        return 'Over 60 years old'\n",
    "\n",
    "def clean_age_column(age) -> str:\n",
    "    \"\"\"Cleans the age column of a dataframe\n",
    "\n",
    "    Args:\n",
    "        age (Any): An int, str or float representing age\n",
    "\n",
    "    Returns:\n",
    "        str: a string based on the age passed\n",
    "    \"\"\"\n",
    "    if isinstance(age, str):\n",
    "        n = age.replace(\" \", \"\")\n",
    "        if 'or' in n:\n",
    "            return age_to_range(int(n[0:2]))\n",
    "                \n",
    "        if 'Under' in n:\n",
    "            return age_to_range(int(n[5:7]))\n",
    "            \n",
    "        if '-' in n:\n",
    "            return age_to_range((int(n[0:2]) + int(n[3:5]))//2)\n",
    "                \n",
    "        if 'Prefer' in n:\n",
    "            return 'Prefer not to say'\n",
    "        \n",
    "        if n is None:\n",
    "            return 'Prefer not to say'\n",
    "            \n",
    "    if isinstance(age, float) or isinstance(age, int):\n",
    "        return age_to_range(round(age))\n",
    "\n",
    "def replace_na_with_mean(df: pd.DataFrame, column_name: str) -> None:\n",
    "    \"\"\"Replaces na values in column of a dataframe with mean\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be modified\n",
    "        column_name (str): column in dataframe\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the column passed does not exist in dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if not column_name in df.columns:\n",
    "        raise ValueError(f\"No column named {column_name} in dataframe.\")\n",
    "    \n",
    "    age_list = df[column_name].to_list()\n",
    "    new_age = []\n",
    "\n",
    "    for age in age_list:\n",
    "        if isinstance(age, str):\n",
    "            n = age.replace(\" \", \"\")\n",
    "            if 'or' in n:\n",
    "                new_age.append(int(n[0:2]))\n",
    "                \n",
    "            if 'Under' in n:\n",
    "                new_age.append(int(n[5:7]))\n",
    "            \n",
    "            if '-' in n:\n",
    "                new_age.append((int(n[0:2]) + int(n[3:5]))//2)\n",
    "                \n",
    "            if 'Prefer' in n or 'None' in n:\n",
    "                new_age.append(np.nan)\n",
    "        \n",
    "        if isinstance(age, float):\n",
    "            if np.isnan(age):\n",
    "                new_age.append(age)\n",
    "            else:\n",
    "                new_age.append(round(age))\n",
    "                \n",
    "    sum_of_numbers = 0\n",
    "    length_of_number = 0\n",
    "    for x in new_age:\n",
    "        if isinstance(x, int):\n",
    "            sum_of_numbers += x\n",
    "            length_of_number += 1 \n",
    "    mean = round(sum_of_numbers/length_of_number)\n",
    "\n",
    "    df[column_name].fillna(mean, inplace=True)\n",
    "  \n",
    "replace_na_with_mean(df2018, 'age')\n",
    "replace_na_with_mean(df2019, 'age')\n",
    "replace_na_with_mean(df2020, 'age')\n",
    "replace_na_with_mean(df2021, 'age')\n",
    "\n",
    "df2018['age'] = df2018['age'].apply(clean_age_column)\n",
    "df2019['age'] = df2019['age'].apply(clean_age_column)\n",
    "df2020['age'] = df2020['age'].apply(clean_age_column)\n",
    "df2021['age'] = df2021['age'].apply(clean_age_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age = pd.DataFrame(df2018['age'], columns=['age'])\n",
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "age = merge_dfs(df_list, 'age')\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'gender')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In the 2018 dataset the choices were male and female but in other datasets its man and woman so changing the 2018 dataset index\n",
    "list_of_choices = []\n",
    "for item in df2018['gender'].to_list():\n",
    "    if isinstance(item, type(None)):\n",
    "        list_of_choices.append(item)\n",
    "        \n",
    "    if isinstance(item, str):\n",
    "        if 'Male' in item:\n",
    "            list_of_choices.append(item.replace('Male', 'Man'))\n",
    "        elif 'Female' in item:\n",
    "            list_of_choices.append(item.replace('Female', 'Woman'))\n",
    "        else:\n",
    "            list_of_choices.append(item)\n",
    "  \n",
    "df2018['gender'] = list_of_choices\n",
    "df2018['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_trans_option(df: pd.DataFrame) -> list:\n",
    "    e = []\n",
    "    for gender, choice in zip(df['gender'].to_list(), df['transgender'].to_list()):\n",
    "        \n",
    "        if isinstance(choice, str) and isinstance(gender, str): \n",
    "            if 'Yes' in choice:\n",
    "                e.append(gender +  ';Transgender')\n",
    "                \n",
    "            if 'No' in choice:\n",
    "                e.append(gender)\n",
    "            \n",
    "            if 'Prefer not to say' in choice or 'Or, in your own words:' in choice:\n",
    "                e.append(None)\n",
    "                \n",
    "        if isinstance(choice, type(None)) or isinstance(gender, type(None)):\n",
    "            e.append(gender)\n",
    "        \n",
    "    return e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019['gender'] = add_trans_option(df2019)\n",
    "df2020['gender'] = add_trans_option(df2020)\n",
    "df2021['gender'] = add_trans_option(df2021)\n",
    "\n",
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "gender = merge_dfs(df_list, 'gender', rename=True, rename_data={'Male': 'Man', 'Female': 'Woman'})\n",
    "gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load that data to production db\n",
    "production_credentials = get_credentials(\"..\\sof_sa\\conf\\prod_db_credentials.json\")\n",
    "load_data_into_db(\"languages\", production_credentials, df=languages)\n",
    "load_data_into_db(\"future_languages\", production_credentials, df=future_languages)\n",
    "load_data_into_db(\"databases\", production_credentials, df=databases)\n",
    "load_data_into_db(\"future_databases\", production_credentials, df=future_databases)\n",
    "load_data_into_db(\"platforms\", production_credentials, df=platforms)\n",
    "load_data_into_db(\"future_platforms\", production_credentials, df=future_platforms)\n",
    "load_data_into_db(\"web_frameworks\", production_credentials, df=web_frameworks)\n",
    "load_data_into_db(\"future_web_frameworks\", production_credentials, df=future_web_frameworks)\n",
    "load_data_into_db(\"age\", production_credentials, df=age)\n",
    "load_data_into_db(\"gender\", production_credentials, df=gender)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (sof_sa)",
   "language": "python",
   "name": "kedro_sof_sa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "28aaa51324a8b83b0e1114aa3e709953fef62500c2d77cbc42898e3a29750585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
