{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing exploratory data analysis on data from the StakeOverFlow developer survey from the years 2018 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The purpose of this notebook is to analyze StackOverflow Developer Survey data in order to answer the following questions:\\\n",
    "***Developer's choice of tech stack?***\\\n",
    "This is question is broken down to four parts namely:\n",
    "- Question 1 Which programming languages have gained popularity from 2018 to 2021?\n",
    "- Question 2 Which database services have gained popularity from 2018 to 2021?\n",
    "- Question 3 Which cloud platforms have gained popularity from 2018 to 2021?\n",
    "- Question 4 Which web frameworks have gained popularity from 2018 to 2021?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "Extracting the data\\\n",
    "Data Model\\\n",
    "Transforming the data\\\n",
    "Loading in the data into a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While writing this notebook, the data was stored locally in my computer therefore to follow along with this note book you will need to download the data from here : https://insights.stackoverflow.com/survey/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\znman\\AppData\\Local\\Temp\\ipykernel_5620\\3155309829.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\znman\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5620\\\\3155309829.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\znman\\AppData\\Local\\Temp\\ipykernel_5620\\3155309829.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\znman\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5620\\\\3155309829.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'catalog'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2018 = catalog.load('public_2018_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis is for practice only as the use is minimal \n",
    "# Here a staging database is used to store raw data from the csv files then loaded back into a dataframe\n",
    "# however an sql query has been executed against the raw data.\n",
    "# This would be useful if there needs to be continuous requests to the vendor and also makes it easy to follow\n",
    "# an alternate transformation route.\n",
    "\n",
    "# load data into staging database\n",
    "catalog.save('stackoverflow2018_dataset', df2018) \n",
    "\n",
    "# Using kedro datasets an sql query is run when the data is loaded back into the pipeline.\n",
    "# See query in catalog file 'sof-sa\\conf\\base\\catalog_sqltables.yml'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2018.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1\n",
    "from collections import Counter\n",
    "\n",
    "def count_unique_items_in_column(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Counts unique elements in dataframe column. Column must have semicolon separated values or nan values in column\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be modified\n",
    "        column_name (str): column name in dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: new dataframe contain value and count of value in df\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the column passed does not exist in dataframe\n",
    "    \"\"\"\n",
    "    if not column_name in df.columns:\n",
    "        raise ValueError(f\"No column named {column_name} in dataframe.\")\n",
    "    \n",
    "    column_as_list = df[column_name].tolist()\n",
    "    \n",
    "    new_list = []\n",
    "    for list_item in column_as_list: \n",
    "        \n",
    "        # for nan values\n",
    "        if isinstance(list_item, type(None)):\n",
    "            new_list.append(list_item)\n",
    "            \n",
    "        if isinstance(list_item, str): \n",
    "            new_list.extend(list_item.split(\";\"))\n",
    "            \n",
    "    # find the number of occurances of a item in a list\n",
    "    occ = Counter(new_list)\n",
    "    language = []\n",
    "    count = []\n",
    "    for x in occ:\n",
    "        key = x\n",
    "        value = occ[key]\n",
    "        language.append(key)\n",
    "        count.append(value)\n",
    "\n",
    "    df_temp = pd.DataFrame(list(zip(language, count)), columns = [column_name, 'count'])\n",
    "    df_temp.set_index(column_name, inplace=True)\n",
    "    df_temp.sort_values(by='count', ascending=False, inplace=True)\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "def _merge(dataframe_list: list) -> pd.DataFrame:\n",
    "    \"\"\"Merges dataframes on index\n",
    "\n",
    "    Args:\n",
    "        dataframe_list (list): a list of dataframes to merge\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: merged dataframe\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: if the list of dataframes passed is not equal to four\n",
    "    \"\"\"\n",
    "    if len(dataframe_list) != 4:\n",
    "        raise ValueError(\"List of dataframes must be equal to four(4)\")\n",
    "        \n",
    "    df18_19 = pd.merge(dataframe_list[0], dataframe_list[1], left_index=True, right_index=True)\n",
    "    df20_21 = pd.merge(dataframe_list[2], dataframe_list[3], left_index=True, right_index=True)\n",
    "    dfs_merged = pd.merge(df18_19, df20_21, left_index=True, right_index=True)\n",
    "    dfs_merged.columns = ['2018', '2019', '2020', '2021']\n",
    "    \n",
    "    return dfs_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "def display_index_values(df_list: list, column_name: str):\n",
    "    for i in df_list:\n",
    "        df_temp = count_unique_items_in_column(i, column_name)\n",
    "        yield df_temp.index.values\n",
    "        \n",
    "j = display_index_values(df_list, 'web_framework_have_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Frameworks\n",
    "# rename React in 2018 dataset to React.js\n",
    "# rename 'Angular' in 2018 dataset to Angular.js\n",
    "# rename 'Angular/Angular.js' to Angular.js in 2019 dataset\n",
    "# add ASP.NET to 2018 dataset and set it to zero\n",
    "# add jQuery to 2018 dataset and set it to zero\n",
    "# add Vue.js to 2018 dataset and set it to zero\n",
    "# add Flask to 2018 dataset and set it to zero\n",
    "# add Laravel to 2018 dataset and set it to zero\n",
    "# add Express to 2018 dataset and set it to zero\n",
    "# add Ruby on Rails to 2018 dataset and set it to zero\n",
    "# add Drupal on Rails to 2018 dataset and set it to zero\n",
    "df18 = count_unique_items_in_column(df2018, 'web_framework_have_worked_with').rename(index={'React': 'React.js', 'Angular': 'Angular.js', 'Angular/Angular.js': 'Angular.js'})\n",
    "for i in ['ASP.NET', 'jQuery', 'Vue.js', 'Flask', 'Laravel',  'Express', 'Ruby on Rails', 'Drupal']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'web_framework_have_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'web_framework_have_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'web_framework_have_worked_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "web_frameworks = _merge(l)\n",
    "\n",
    "\n",
    "df18 = count_unique_items_in_column(df2018, 'web_framework_want_to_work_with').rename(index={'React': 'React.js', 'Angular': 'Angular.js', 'Angular/Angular.js': 'Angular.js'})\n",
    "for i in ['ASP.NET', 'jQuery', 'Vue.js', 'Flask', 'Laravel',  'Express', 'Ruby on Rails', 'Drupal']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'web_framework_want_to_work_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'web_framework_want_to_work_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'web_framework_want_to_work_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "future_web_frameworks = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'platform_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platforms\n",
    "# Only dealing with cloud platforms : AWS Microsoft Azure Heroku  Google Cloud Platform\t IBM Cloud or Watson\n",
    "# change 'Google Cloud Platform/App Engine' into 'Google Cloud Platform'\n",
    "# change 'Azure' in 2018 dataset to 'Microsoft Azure'\n",
    "df18 = count_unique_items_in_column(df2018, 'platform_worked_with').rename(index={'Google Cloud Platform/App Engine': 'Google Cloud Platform', 'Azure': 'Microsoft Azure'})\n",
    "df19 = count_unique_items_in_column(df2019, 'platform_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'platform_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'platform_worked_with')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "platforms = _merge(l)\n",
    "\n",
    "df18 = count_unique_items_in_column(df2018, 'platform_desire_next_year').rename(index={'Google Cloud Platform/App Engine': 'Google Cloud Platform', 'Azure': 'Microsoft Azure'})\n",
    "df19 = count_unique_items_in_column(df2019, 'platform_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'platform_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'platform_desire_next_year')\n",
    "\n",
    "l = [df18, df19, df20, df21]\n",
    "future_platforms = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'language_worked_with')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Languages\n",
    "df18 = count_unique_items_in_column(df2018, 'language_worked_with')\n",
    "df19 = count_unique_items_in_column(df2019, 'language_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'language_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'language_worked_with')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "languages = _merge(l)\n",
    "\n",
    "# future_languages\n",
    "df18 = count_unique_items_in_column(df2018, 'language_desire_next_year')\n",
    "df19 = count_unique_items_in_column(df2019, 'language_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'language_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'language_desire_next_year')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "future_languages = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'database_desire_next_year')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases\n",
    "df18 = count_unique_items_in_column(df2018, 'database_worked_with').rename(index={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'})\n",
    "for i in ['Cassandra', 'Couchbase', 'Firebase']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'database_worked_with')\n",
    "df20 = count_unique_items_in_column(df2020, 'database_worked_with')\n",
    "df21 = count_unique_items_in_column(df2021, 'database_worked_with')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "databases = _merge(l)\n",
    "\n",
    "# future_Databases\n",
    "df18 = count_unique_items_in_column(df2018, 'database_desire_next_year').rename(index={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'})\n",
    "for i in ['Couchbase', 'Firebase']:\n",
    "    if i not in df18.index.values:\n",
    "        df18.loc[i] = 0\n",
    "df19 = count_unique_items_in_column(df2019, 'database_desire_next_year')\n",
    "df20 = count_unique_items_in_column(df2020, 'database_desire_next_year')\n",
    "df21 = count_unique_items_in_column(df2021, 'database_desire_next_year')\n",
    "l = [df18, df19, df20, df21]\n",
    "\n",
    "future_databases = _merge(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_dfs(df_list: list, column_name: str, rename: bool = False, rename_data: dict = {}, fill_missing: bool = False, missing_values: dict = {}):\n",
    "    \"\"\"Merge dataframes into one dataframe. \n",
    "\n",
    "    Args:\n",
    "        df_list (list): list of dataframes to merge\n",
    "        column_name (str): column name to merge dataframes on\n",
    "        rename (bool, optional): option to rename any values or not. Defaults to False.\n",
    "        rename_data (dict, optional): data for renaming. Defaults to {}.\n",
    "        fill_missing (bool, optional): fill in missing data or not. Defaults to False.\n",
    "        missing_values (dict, optional): missing data values. Defaults to {}.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if rename is set to true but no data provided\n",
    "        ValueError: if fill_missing is set to true but no data provided\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : merged dataframe\n",
    "    \"\"\"\n",
    "    if rename:\n",
    "        if len(rename_data) == 0:\n",
    "            raise ValueError('Rename specified as True but no data provided')\n",
    "        \n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name).rename(index=rename_data)\n",
    "    else: \n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name)\n",
    "        \n",
    "    if fill_missing:\n",
    "        if len(missing_values) == 0:\n",
    "            raise ValueError('Fill missing specified as True but no data provided')\n",
    "        \n",
    "        if not rename:\n",
    "            df18 = count_unique_items_in_column(df_list[0], column_name)\n",
    "            \n",
    "        for i in missing_values:\n",
    "            if i not in df18.index.values:\n",
    "                df18.loc[i] = 0\n",
    "                \n",
    "    if not rename and not fill_missing:\n",
    "        df18 = count_unique_items_in_column(df_list[0], column_name) \n",
    "        \n",
    "    df19 = count_unique_items_in_column(df_list[1], column_name)\n",
    "    df20 = count_unique_items_in_column(df_list[2], column_name)\n",
    "    df21 = count_unique_items_in_column(df_list[3], column_name)\n",
    "    \n",
    "    l = [df18, df19, df20, df21]\n",
    "\n",
    "    dfs_merged = _merge(l)\n",
    "    return dfs_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "df = merge_dfs(df_list, 'database_worked_with', rename=True, rename_data={'SQL Server': 'Microsoft SQL Server', 'IBM Db2': 'IBM DB2', 'Amazon DynamoDB': 'DynamoDB'}, fill_missing=True, missing_values=['Cassandra', 'Couchbase', 'Firebase'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!!! Transformations for question 1 done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2\n",
    "\n",
    "def age_to_range(number: int) -> str:\n",
    "    \"\"\"Checks if a certain value falls within a certain range then retruns the appropriate string\n",
    "\n",
    "    Args:\n",
    "        number (int): number to be checked\n",
    "\n",
    "    Returns:\n",
    "        str: a string based on the number passed\n",
    "    \"\"\"\n",
    "\n",
    "    if number < 18:\n",
    "        return 'Under 18 years old'\n",
    "    elif number >= 18 and number <= 24:\n",
    "        return '18 - 24 years old'\n",
    "    elif number >= 25 and number <= 30:\n",
    "        return '25 - 30 years old'\n",
    "    elif number >= 31 and number <= 36:\n",
    "        return '31 - 36 years old'\n",
    "    elif number >= 37 and number <= 42:\n",
    "        return '37 - 42 years old'\n",
    "    elif number >= 43 and number <= 48:\n",
    "        return '43 - 48 years old'\n",
    "    elif number >= 49 and number <= 54:\n",
    "        return '49 - 54 years old'\n",
    "    elif number >= 55 and number <= 60:\n",
    "        return '55 - 60 years old'\n",
    "    elif number > 60:\n",
    "        return 'Over 60 years old'\n",
    "\n",
    "def clean_age_column(age) -> str:\n",
    "    \"\"\"Cleans the age column of a dataframe\n",
    "\n",
    "    Args:\n",
    "        age (Any): An int, str or float representing age\n",
    "\n",
    "    Returns:\n",
    "        str: a string based on the age passed\n",
    "    \"\"\"\n",
    "    if isinstance(age, str):\n",
    "        n = age.replace(\" \", \"\")\n",
    "        if 'or' in n:\n",
    "            return age_to_range(int(n[0:2]))\n",
    "                \n",
    "        if 'Under' in n:\n",
    "            return age_to_range(int(n[5:7]))\n",
    "            \n",
    "        if '-' in n:\n",
    "            return age_to_range((int(n[0:2]) + int(n[3:5]))//2)\n",
    "                \n",
    "        if 'Prefer' in n:\n",
    "            return 'Prefer not to say'\n",
    "        \n",
    "        if n is None:\n",
    "            return 'Prefer not to say'\n",
    "            \n",
    "    if isinstance(age, float) or isinstance(age, int):\n",
    "        return age_to_range(round(age))\n",
    "\n",
    "def replace_na_with_mean(df: pd.DataFrame, column_name: str) -> None:\n",
    "    \"\"\"Replaces na values in column of a dataframe with mean\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be modified\n",
    "        column_name (str): column in dataframe\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the column passed does not exist in dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if not column_name in df.columns:\n",
    "        raise ValueError(f\"No column named {column_name} in dataframe.\")\n",
    "    \n",
    "    age_list = df[column_name].to_list()\n",
    "    new_age = []\n",
    "\n",
    "    for age in age_list:\n",
    "        if isinstance(age, str):\n",
    "            n = age.replace(\" \", \"\")\n",
    "            if 'or' in n:\n",
    "                new_age.append(int(n[0:2]))\n",
    "                \n",
    "            if 'Under' in n:\n",
    "                new_age.append(int(n[5:7]))\n",
    "            \n",
    "            if '-' in n:\n",
    "                new_age.append((int(n[0:2]) + int(n[3:5]))//2)\n",
    "                \n",
    "            if 'Prefer' in n or 'None' in n:\n",
    "                new_age.append(np.nan)\n",
    "        \n",
    "        if isinstance(age, float):\n",
    "            if np.isnan(age):\n",
    "                new_age.append(age)\n",
    "            else:\n",
    "                new_age.append(round(age))\n",
    "                \n",
    "    sum_of_numbers = 0\n",
    "    length_of_number = 0\n",
    "    for x in new_age:\n",
    "        if isinstance(x, int):\n",
    "            sum_of_numbers += x\n",
    "            length_of_number += 1 \n",
    "    mean = round(sum_of_numbers/length_of_number)\n",
    "\n",
    "    df[column_name].fillna(mean, inplace=True)\n",
    "  \n",
    "replace_na_with_mean(df2018, 'age')\n",
    "replace_na_with_mean(df2019, 'age')\n",
    "replace_na_with_mean(df2020, 'age')\n",
    "replace_na_with_mean(df2021, 'age')\n",
    "\n",
    "df2018['age'] = df2018['age'].apply(clean_age_column)\n",
    "df2019['age'] = df2019['age'].apply(clean_age_column)\n",
    "df2020['age'] = df2020['age'].apply(clean_age_column)\n",
    "df2021['age'] = df2021['age'].apply(clean_age_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age = pd.DataFrame(df2018['age'], columns=['age'])\n",
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "age = merge_dfs(df_list, 'age')\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = display_index_values(df_list, 'gender')\n",
    "\n",
    "for i in j:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In the 2018 dataset the choices were male and female but in other datasets its man and woman so changing the 2018 dataset index\n",
    "list_of_choices = []\n",
    "for item in df2018['gender'].to_list():\n",
    "    if isinstance(item, type(None)):\n",
    "        list_of_choices.append(item)\n",
    "        \n",
    "    if isinstance(item, str):\n",
    "        if 'Male' in item:\n",
    "            list_of_choices.append(item.replace('Male', 'Man'))\n",
    "        elif 'Female' in item:\n",
    "            list_of_choices.append(item.replace('Female', 'Woman'))\n",
    "        else:\n",
    "            list_of_choices.append(item)\n",
    "  \n",
    "df2018['gender'] = list_of_choices\n",
    "df2018['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_trans_option(df: pd.DataFrame) -> list:\n",
    "    e = []\n",
    "    for gender, choice in zip(df['gender'].to_list(), df['transgender'].to_list()):\n",
    "        \n",
    "        if isinstance(choice, str) and isinstance(gender, str): \n",
    "            if 'Yes' in choice:\n",
    "                e.append(gender +  ';Transgender')\n",
    "                \n",
    "            if 'No' in choice:\n",
    "                e.append(gender)\n",
    "            \n",
    "            if 'Prefer not to say' in choice or 'Or, in your own words:' in choice:\n",
    "                e.append(None)\n",
    "                \n",
    "        if isinstance(choice, type(None)) or isinstance(gender, type(None)):\n",
    "            e.append(gender)\n",
    "        \n",
    "    return e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019['gender'] = add_trans_option(df2019)\n",
    "df2020['gender'] = add_trans_option(df2020)\n",
    "df2021['gender'] = add_trans_option(df2021)\n",
    "\n",
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "gender = merge_dfs(df_list, 'gender', rename=True, rename_data={'Male': 'Man', 'Female': 'Woman'})\n",
    "gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load that data to production db\n",
    "production_credentials = get_credentials(\"..\\sof_sa\\conf\\prod_db_credentials.json\")\n",
    "load_data_into_db(\"languages\", production_credentials, df=languages)\n",
    "load_data_into_db(\"future_languages\", production_credentials, df=future_languages)\n",
    "load_data_into_db(\"databases\", production_credentials, df=databases)\n",
    "load_data_into_db(\"future_databases\", production_credentials, df=future_databases)\n",
    "load_data_into_db(\"platforms\", production_credentials, df=platforms)\n",
    "load_data_into_db(\"future_platforms\", production_credentials, df=future_platforms)\n",
    "load_data_into_db(\"web_frameworks\", production_credentials, df=web_frameworks)\n",
    "load_data_into_db(\"future_web_frameworks\", production_credentials, df=future_web_frameworks)\n",
    "load_data_into_db(\"age\", production_credentials, df=age)\n",
    "load_data_into_db(\"gender\", production_credentials, df=gender)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (sof_sa)",
   "language": "python",
   "name": "kedro_sof_sa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "28aaa51324a8b83b0e1114aa3e709953fef62500c2d77cbc42898e3a29750585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
