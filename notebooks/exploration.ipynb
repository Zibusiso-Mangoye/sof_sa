{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing exploratory data analysis on data from the StakeOverFlow developer survey from the years 2018 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table of Contents\n",
    "\n",
    "Phase 1 : Extracting the data\n",
    "- Exploring the data\n",
    "- Data Modelling\n",
    "        \n",
    "Phase 2 : Transforming the data\n",
    "- Cleaning the data\n",
    "- Merging dataframes\n",
    "- Cleaning the new dataframe\n",
    "\n",
    "Phase 3 : Loading the data\n",
    "- Loading in the data into a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While writing this notebook, the data was stored locally in my computer therefore to follow along with this note book you will need to download the data from here : https://insights.stackoverflow.com/survey/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#setting the maximum display for the notebook cells \n",
    "pd.set_option('display.max_rows', 48)\n",
    "pd.set_option('display.max_columns', 48)\n",
    "\n",
    "#removing warnings \n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation - *The number of survey participants has been decreasing from 2018 to 2020 even though the survey length is becoming shorter. Except for the year 2021 which has seen an increase in survey participant and decreasing survey length. Since the 2021 dataset has fewer columns, it is the primary dataset and a subsest of the other datasets will be taken in order to answer the following questions:*\n",
    "\n",
    "#### Question 1. *How much impact has the pandemic had on developer's choices of tech stack?*\n",
    "This is question is broken down to three parts namely:\n",
    "\n",
    "##### Question 1.1 Which programming languages have gained popularity from 2018 to 2021?\n",
    "columns needed : ResponseId, LanguageHaveWorkedWith, LanguageWantToWorkWith\n",
    "\n",
    "##### Question 1.2 Which database services have gained popularity from 2018 to 2021?\n",
    "columns needed : ResponseId, DatabaseHaveWorkedWith, DatabaseWantToWorkWith\n",
    "\n",
    "##### Question 1.3 Which platforms and frameworks have gained popularity from 2018 to 2021?\n",
    "columns needed : ResponseId, WebframeHaveWorkedWith, WebframeWantToWorkWith, MiscTechHaveWorkedWith,    MiscTechWantToWorkWith, PlatformHaveWorkedWith, PlatformWantToWorkWith\n",
    "\n",
    "#### Question 2. *How has the distribution of gender, age and ethnicity in the developer community changed from 2018 to 2021?*\n",
    "columns needed : ResponseId, Age, Ethnicity, Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "def get_credentials(filepath : str) -> dict:\n",
    "    \"\"\"Loads database credentials from file.\n",
    "    Args: \n",
    "        filepath - path to the json file\n",
    "\n",
    "    Returns :\n",
    "        A dictionary containing database credentials\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        data = json.loads(file.read())\n",
    "   \n",
    "    return data\n",
    "credentials = get_credentials(\"..\\sof_sa\\conf\\staging_db_credentials.json\")\n",
    "\n",
    "# TO DO: EXPORT TO UTILITY FUNCTIONS\n",
    "def execute_sql(path_to_sql_file: str, credentials: dict) -> pd.DataFrame:\n",
    "    \"\"\"Executes an sql query \n",
    "\n",
    "    Args:\n",
    "        path_to_sql_file (str): path to the sql file that contains the sql statement to execute.\n",
    "        credentials (dict): credentials to the database where the query will be executed \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a pandas dataframe representing the results of the query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        DATABASE_URL = f'postgresql+psycopg2://{credentials[\"user\"]}:{credentials[\"password\"]}@{credentials[\"host\"]}:{credentials[\"port\"]}/{credentials[\"database\"]}'\n",
    "        engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "        with open(path_to_sql_file, 'r') as file, engine.connect() as connection:\n",
    "            df = pd.read_sql_query(file.read(), connection)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "    \n",
    "df2018 = execute_sql(\"..\\sof_sa\\SQL\\select_2018_data.sql\", credentials)\n",
    "df2019 = execute_sql(\"..\\sof_sa\\SQL\\select_2019_data.sql\", credentials)\n",
    "df2020 = execute_sql(\"..\\sof_sa\\SQL\\select_2020_data.sql\", credentials)\n",
    "df2021 = execute_sql(\"..\\sof_sa\\SQL\\select_2021_data.sql\", credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2018 has shape : (98855, 13)\n",
      "df2019 has shape : (88883, 13)\n",
      "df2020 has shape : (64461, 13)\n",
      "df2021 has shape : (83439, 13)\n"
     ]
    }
   ],
   "source": [
    "# The size of the different datasets\n",
    "print(f\"df2018 has shape : {df2018.shape}\")\n",
    "print(f\"df2019 has shape : {df2019.shape}\")\n",
    "print(f\"df2020 has shape : {df2020.shape}\")\n",
    "print(f\"df2021 has shape : {df2021.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Model](../img/model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before creating tables, all the datasets are joined to create one dataframe that can then be subdivided into tables. The question of which web framework the respondents used or would like to use was not asked in 2018, so framework in general will be used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335638, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [df2018, df2019, df2020, df2021]\n",
    "df_all = pd.concat(df_list)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inspecting each column and cleaning it if necessary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['respondent', 'age', 'ethnicity', 'gender', 'database_desire_next_year',\n",
       "       'database_worked_with', 'language_desire_next_year',\n",
       "       'language_worked_with', 'platform_desire_next_year',\n",
       "       'platform_worked_with', 'web_framework_have_worked_with',\n",
       "       'web_framework_want_to_work_with', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '18 - 24 years old', '55 - 64 years old',\n",
       "       '35 - 44 years old', '25 - 34 years old', '45 - 54 years old',\n",
       "       'Under 18 years old', '65 years or older', nan, 18.0, 23.0, 19.0,\n",
       "       49.0, 25.0, 20.0, 31.0, 14.0, 13.0, 71.0, 26.0, 69.0, 66.0, 15.0,\n",
       "       36.0, 44.0, 33.0, 43.0, 83.0, 32.0, 29.0, 16.0, 30.0, 13.5, 17.0,\n",
       "       58.0, 65.0, 99.0, 12.0, 50.0, 22.0, 24.0, 21.0, 37.0, 76.0, 60.0,\n",
       "       81.0, 45.0, 54.0, 59.0, 61.0, 88.0, 42.0, 35.0, 73.0, 67.0, 38.0,\n",
       "       27.0, 9.0, 28.0, 63.0, 64.0, 39.0, 52.0, 77.0, 47.0, 34.0, 62.0,\n",
       "       41.0, 40.0, 56.0, 46.0, 51.0, 48.0, 57.0, 23.9, 55.0, 68.0, 1.0,\n",
       "       53.0, 17.5, 70.0, 16.5, 46.5, 11.0, 3.0, 97.0, 29.5, 78.0, 74.0,\n",
       "       26.5, 26.3, 24.5, 72.0, 10.0, 75.0, 79.0, 36.8, 14.1, 19.5, 98.0,\n",
       "       43.5, 22.5, 31.5, 21.5, 28.5, 33.6, 2.0, 38.5, 30.8, 24.8, 90.0,\n",
       "       61.3, 4.0, 17.3, 19.9, 80.0, 85.0, 23.5, 16.9, 20.9, 91.0, 98.9,\n",
       "       57.9, 94.0, 95.0, 37.5, 14.5, 5.0, 82.0, 84.0, 37.3, 33.5, 53.8,\n",
       "       31.4, 87.0, 14.7, 49.5, 26.8, 86.0, 15.5, 35.7, 32.5, 23.8, 96.0,\n",
       "       34.5, 20.5, 279.0, 27.5, 32.8, 89.0, 19.8, 7.0, 39.5, 23.4,\n",
       "       '35-44 years old', '18-24 years old', '25-34 years old',\n",
       "       '55-64 years old', '45-54 years old', 'Prefer not to say'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respondents is not important as we are not going to be checking for individual preferences.\n",
    "# age column\n",
    "df_all['age'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length b4 : 335638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    335638\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for values that are in range form: \n",
    "#   - take the average of the two values and use it as age\n",
    "# for values with one value and text\n",
    "#   - take the value and discard text\n",
    "# for entries with value 'prefer not to say'\n",
    "#   - replace with nan\n",
    "# for values of type float \n",
    "#   - round off and convert to int\n",
    "\n",
    "from math import isnan \n",
    "\n",
    "age_list = list(df_all['age'])\n",
    "print(f\"length b4 : {len(age_list)}\")\n",
    "new_age = []\n",
    "\n",
    "for age in age_list:\n",
    "    if isinstance(age, str):\n",
    "        n = age.replace(\" \", \"\")\n",
    "        if 'or' in n:\n",
    "            new_age.append(int(n[0:2]))\n",
    "            \n",
    "        if 'Under' in n:\n",
    "            new_age.append(int(n[5:7]))\n",
    "        \n",
    "        if '-' in n:\n",
    "            new_age.append((int(n[0:2]) + int(n[3:5]))//2)\n",
    "            \n",
    "        if 'Prefer' in n or 'None' in n:\n",
    "            new_age.append(np.nan)\n",
    "        \n",
    "    if isinstance(age, float):\n",
    "        if isnan(age):\n",
    "            new_age.append(age)\n",
    "        else:\n",
    "            new_age.append(round(age))\n",
    "            \n",
    "    if isinstance(age, type(None)):\n",
    "        new_age.append(age)\n",
    "            \n",
    "# replacing the column Age with the new ages\n",
    "df_all['age'] = new_age\n",
    "\n",
    "# replacing nan values with the mean of the column for a specific year\n",
    "def calculate_mean_of_column(df: pd.DataFrame, column: str, filter_column: str, filter_value: int):\n",
    "    \"\"\"Calculates the mean of a column in a dataframe based on filter column and filter value\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be filtered.\n",
    "        column (str): column in df whose mean is to be calculated.\n",
    "        filter_column (str): name of column in df to be used as a filter.\n",
    "        filter_value (str): value to filter the filter column on.\n",
    "\n",
    "    Returns:\n",
    "        int representing the mean.\n",
    "    \"\"\"\n",
    "    mean = df[df[filter_column] == filter_value][column].mean(skipna=True)\n",
    "    return round(mean)\n",
    "\n",
    "from statistics import mean\n",
    "mean2018 = calculate_mean_of_column(df_all, 'age', 'year', 2018)\n",
    "mean2019 = calculate_mean_of_column(df_all, 'age', 'year', 2019)\n",
    "mean2020 = calculate_mean_of_column(df_all, 'age', 'year', 2020)\n",
    "mean2021 = calculate_mean_of_column(df_all, 'age', 'year', 2021)\n",
    "\n",
    "list_of_means = [mean2018, mean2019, mean2020, mean2021]\n",
    "avg_mean = round(mean(list_of_means))\n",
    "\n",
    "# for some reason inplace is not working\n",
    "df_all['age'].fillna(avg_mean, inplace=True)\n",
    "\n",
    "# age column is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White or of European descent                                                                                                                                                                   163459\n",
       "South Asian                                                                                                                                                                                     27381\n",
       "East Asian                                                                                                                                                                                      10488\n",
       "Middle Eastern                                                                                                                                                                                   8961\n",
       "Black or of African descent                                                                                                                                                                      7143\n",
       "                                                                                                                                                                                                ...  \n",
       "East Asian;Native American, Pacific Islander, or Indigenous Australian;South Asian;Biracial;Multiracial                                                                                             1\n",
       "East Asian;Native American, Pacific Islander, or Indigenous Australian;South Asian;White or of European descent                                                                                     1\n",
       "White or of European descent;Multiracial;Middle Eastern;Or, in your own words:;Black or of African descent;Indigenous (such as Native American, Pacific Islander, or Indigenous Australian)         1\n",
       "White or of European descent;I don't know;Or, in your own words:;Indigenous (such as Native American, Pacific Islander, or Indigenous Australian)                                                   1\n",
       "Southeast Asian;Hispanic or Latino/a/x;East Asian;Biracial                                                                                                                                          1\n",
       "Name: ethnicity, Length: 714, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ethnicity column\n",
    "df_all['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1.1\n",
    "def count_unique_items_incolumn(df, column):\n",
    "    ''' Separates colon(;) separated items in a column into individual items in a list and calculates the number of occurances of eaach item.\n",
    "        input : a pandas dataframe, a column in df that contains colon separated values(a;b)\n",
    "        output : a sorted dataframe on count with each item and its count\n",
    "    '''\n",
    "    new_list = []\n",
    "    for lang in list(df[column]):\n",
    "        new_items = lang.split(\";\")\n",
    "        new_items = map(lambda x: x.strip(), new_items)\n",
    "        new_list.extend(new_items)\n",
    "\n",
    "    \n",
    "\n",
    "def df_column_to_list(df: pd.DataFrame, column_name: str) -> list:\n",
    "    \"\"\"Converts a given dataframe into a list\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to be modified\n",
    "        column_name (str): column name to be converted in dataframe\n",
    "\n",
    "    Returns:\n",
    "        list: column items in list form\n",
    "    \"\"\"\n",
    "    col_list = df[column_name].tolist()\n",
    "    \n",
    "    new_list = []\n",
    "    for list_item in col_list: \n",
    "        \n",
    "        # for nan values\n",
    "        if type(list_item) == float:\n",
    "            new_list.append(list_item)\n",
    "            \n",
    "        if type(list_item) == list:\n",
    "            singleitem = next(iter(list_item.split(';')))\n",
    "            new_list.append(singleitem)\n",
    "            \n",
    "        if type(list_item) == str: \n",
    "            singleitem = next(iter(list_item.split(';')))\n",
    "            new_list.append(singleitem)\n",
    "            \n",
    "    # find the number of occurances of a item in a list\n",
    "    occ = Counter(new_list)\n",
    "    language = []\n",
    "    count = []\n",
    "    for x in occ:\n",
    "        key = x\n",
    "        value = occ[key]\n",
    "        language.append(key)\n",
    "        count.append(value)\n",
    "\n",
    "    df_temp = pd.DataFrame(list(zip(language, count)), columns = [column, 'count'])\n",
    "    df_temp.set_index(column, inplace=True)\n",
    "    df_temp.sort_values(by='count', ascending=True, inplace=True)\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "def create_df(columns: list, data: list = None) -> pd.DataFrame:\n",
    "    \"\"\"Creates a dataframe using the data provided and names the columns according the columns lists\n",
    "\n",
    "    Args:\n",
    "        columns (list): name of columns to be used in the dataframe.\n",
    "        data (list, optional): a list of lists that is the data to be used in the dataframe. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if no data is provided.\n",
    "        ValueError: if the length of the data provided is not equal to three.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe from the data.\n",
    "    \"\"\"\n",
    "    if data is None:\n",
    "        raise ValueError(\"No data provided.\")\n",
    "    \n",
    "    if len(data) != 3:\n",
    "        raise ValueError(\"Length of data must be 3.\")\n",
    "    \n",
    "    difference = len(data[0]) - len(data[1])\n",
    "    \n",
    "    # get the number of elements missing\n",
    "    no_missing_elements = abs(difference)\n",
    "    \n",
    "    if difference < 0: \n",
    "        # first list is smaller than second list so fix first list\n",
    "        # then add that to small list\n",
    "        new_values = [\"None\"]*no_missing_elements\n",
    "        data[0].extend(new_values)\n",
    "    \n",
    "    if difference > 0:\n",
    "        # second list is smaller so fix second list \n",
    "        # then add that to small list\n",
    "        new_values = [\"None\"]*no_missing_elements\n",
    "        data[1].extend(new_values)\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(data[0], data[1], data[3])), columns=columns)\n",
    "    df.index.rename(\"respondent\", inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages_worked_with</th>\n",
       "      <th>languages_want_to_work_with</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Objective-C</td>\n",
       "      <td>Objective-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HTML/CSS</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64456</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64457</th>\n",
       "      <td>Assembly</td>\n",
       "      <td>Assembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64458</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64459</th>\n",
       "      <td>HTML/CSS</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64460</th>\n",
       "      <td>C#</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64461 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           languages_worked_with languages_want_to_work_with\n",
       "respondent                                                  \n",
       "0                             C#                          C#\n",
       "1                     JavaScript                      Python\n",
       "2                    Objective-C                 Objective-C\n",
       "3                            NaN                         NaN\n",
       "4                       HTML/CSS                        Java\n",
       "...                          ...                         ...\n",
       "64456                        NaN                         NaN\n",
       "64457                   Assembly                    Assembly\n",
       "64458                        NaN                         NaN\n",
       "64459                   HTML/CSS                    HTML/CSS\n",
       "64460                         C#                          C#\n",
       "\n",
       "[64461 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns needed : ResponseId, LanguageHaveWorkedWith, LanguageWantToWorkWith\n",
    "\n",
    "languages_worked_with = df_column_to_list(df_2021, 'LanguageWorkedWith')\n",
    "languages_want_to_work_with = df_column_to_list(df_2021, 'LanguageDesireNextYear')\n",
    "\n",
    "languages_worked_with = df_column_to_list(df_2021, 'LanguageWorkedWith')\n",
    "languages_want_to_work_with = df_column_to_list(df_2021, 'LanguageDesireNextYear')\n",
    "\n",
    "languages_worked_with = df_column_to_list(df_2021, 'LanguageWorkedWith')\n",
    "languages_want_to_work_with = df_column_to_list(df_2021, 'LanguageDesireNextYear')\n",
    "\n",
    "languages_worked_with = df_column_to_list(df_2021, 'LanguageWorkedWith')\n",
    "languages_want_to_work_with = df_column_to_list(df_2021, 'LanguageDesireNextYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "languages_worked_with = df_column_to_list(df_2021, 'LanguageWorkedWith')\n",
    "languages_want_to_work_with = df_column_to_list(df_2021, 'LanguageDesireNextYear')\n",
    "print(dict(Counter(languages_worked_with)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tables for question 1.2\n",
    "# columns needed : ResponseId, DatabaseHaveWorkedWith, DatabaseWantToWorkWith\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tables for question 1.3\n",
    "# columns needed : ResponseId, WebframeHaveWorkedWith, WebframeWantToWorkWith, MiscTechHaveWorkedWith,    MiscTechWantToWorkWith, PlatformHaveWorkedWith, PlatformWantToWorkWith\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tables for question 2\n",
    "# columns needed : ResponseId, Age, Ethnicity, Gender"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0c98c8edbe3097da9b1ed79db56cd04922f86d5ad07ab3cd840fdb6d8eb2203"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('py39_dataeng': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
